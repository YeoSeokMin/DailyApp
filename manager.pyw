"""
DailyApp ê´€ë¦¬ í”„ë¡œê·¸ë¨
ì‹¤ì‹œê°„ ë¡œê·¸ + ìƒíƒœ í‘œì‹œ + Local LLM ëª¨ë‹ˆí„°ë§
"""

import tkinter as tk
from tkinter import ttk, scrolledtext
import subprocess
import os
import threading
import queue
import time
from datetime import datetime
import urllib.request
import json
import socket

PROJECT_DIR = os.path.dirname(os.path.abspath(__file__))

def check_ollama_running():
    """Ollama ì„œë²„ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸"""
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(1)
        result = sock.connect_ex(('127.0.0.1', 11434))
        sock.close()
        return result == 0
    except:
        return False

def get_ollama_models():
    """Ollama ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        req = urllib.request.Request('http://127.0.0.1:11434/api/tags')
        with urllib.request.urlopen(req, timeout=2) as response:
            data = json.loads(response.read().decode('utf-8'))
            return [m['name'] for m in data.get('models', [])]
    except:
        return []

def get_running_models():
    """í˜„ì¬ ë¡œë“œëœ(ì‹¤í–‰ ì¤‘ì¸) ëª¨ë¸ ì¡°íšŒ"""
    try:
        req = urllib.request.Request('http://127.0.0.1:11434/api/ps')
        with urllib.request.urlopen(req, timeout=2) as response:
            data = json.loads(response.read().decode('utf-8'))
            return [m['name'] for m in data.get('models', [])]
    except:
        return []

def warmup_model(model_name):
    """ëª¨ë¸ ì›œì—… (ë¯¸ë¦¬ ë¡œë“œ)"""
    try:
        data = json.dumps({
            "model": model_name,
            "prompt": "Hi",
            "stream": False,
            "options": {"num_predict": 1}
        }).encode('utf-8')

        req = urllib.request.Request(
            'http://127.0.0.1:11434/api/generate',
            data=data,
            headers={'Content-Type': 'application/json'}
        )
        with urllib.request.urlopen(req, timeout=120) as response:
            return True
    except:
        return False

# ì‚¬ìš©í•  ëª¨ë¸
DEFAULT_MODEL = "qwen2.5:7b-instruct-q5_K_M"

def unload_model(model_name):
    """ëª¨ë¸ ì–¸ë¡œë“œ (GPU ë©”ëª¨ë¦¬ í•´ì œ)"""
    try:
        result = subprocess.run(
            f"ollama stop {model_name}",
            shell=True,
            capture_output=True,
            text=True,
            timeout=30,
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0
        )
        return result.returncode == 0
    except:
        return False

class DailyAppManager:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("DailyApp Manager")
        self.root.geometry("500x920")
        self.root.resizable(False, False)
        self.root.configure(bg="#0f0f1a")

        self.log_queue = queue.Queue()
        self.llm_log_queue = queue.Queue()  # Local LLM ë¡œê·¸ í
        self.is_running = False
        self.auto_run_enabled = True  # ìì • ìë™ì‹¤í–‰ í™œì„±í™”
        self.last_auto_run_date = None  # ë§ˆì§€ë§‰ ìë™ì‹¤í–‰ ë‚ ì§œ
        self.ollama_running = False  # Ollama ì‹¤í–‰ ìƒíƒœ
        self.ollama_process = None  # Ollama í”„ë¡œì„¸ìŠ¤

        self.create_widgets()
        self.center_window()
        self.update_status()
        self.process_log_queue()
        self.process_llm_log_queue()  # LLM ë¡œê·¸ í ì²˜ë¦¬
        self.check_midnight()  # ìì • ì²´í¬ ì‹œì‘
        self.check_ollama_status()  # Ollama ìƒíƒœ ì²´í¬ ì‹œì‘

    def center_window(self):
        self.root.update_idletasks()
        x = (self.root.winfo_screenwidth() - 500) // 2
        y = (self.root.winfo_screenheight() - 920) // 2
        self.root.geometry(f"500x920+{x}+{y}")

    def create_widgets(self):
        # í—¤ë”
        header_frame = tk.Frame(self.root, bg="#0f0f1a")
        header_frame.pack(fill="x", padx=20, pady=(20, 10))

        title = tk.Label(
            header_frame,
            text="DailyApp",
            font=("Segoe UI", 28, "bold"),
            fg="#e94560",
            bg="#0f0f1a"
        )
        title.pack(side="left")

        # ìƒíƒœ ì¸ë””ì¼€ì´í„°
        self.status_dot = tk.Label(
            header_frame,
            text="â—",
            font=("Segoe UI", 14),
            fg="#888888",
            bg="#0f0f1a"
        )
        self.status_dot.pack(side="right", padx=(0, 5))

        self.status_text = tk.Label(
            header_frame,
            text="ëŒ€ê¸° ì¤‘",
            font=("Segoe UI", 11),
            fg="#888888",
            bg="#0f0f1a"
        )
        self.status_text.pack(side="right")

        # ìŠ¤ì¼€ì¤„ ìƒíƒœ ì¹´ë“œ
        schedule_frame = tk.Frame(self.root, bg="#1a1a2e", highlightbackground="#2a2a4e", highlightthickness=1)
        schedule_frame.pack(fill="x", padx=20, pady=10)

        schedule_inner = tk.Frame(schedule_frame, bg="#1a1a2e")
        schedule_inner.pack(fill="x", padx=15, pady=12)

        tk.Label(
            schedule_inner,
            text="â° ìë™ì‹¤í–‰",
            font=("Segoe UI", 11, "bold"),
            fg="#ffffff",
            bg="#1a1a2e"
        ).pack(side="left")

        self.schedule_status = tk.Label(
            schedule_inner,
            text="ì¼œì§ (ë§¤ì¼ 00:00)",
            font=("Segoe UI", 11),
            fg="#4ecca3",
            bg="#1a1a2e"
        )
        self.schedule_status.pack(side="right")

        # ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê°„
        self.last_run_label = tk.Label(
            schedule_frame,
            text="",
            font=("Segoe UI", 9),
            fg="#666666",
            bg="#1a1a2e"
        )
        self.last_run_label.pack(anchor="w", padx=15, pady=(0, 10))

        # Local LLM ìƒíƒœ ì¹´ë“œ
        llm_frame = tk.Frame(self.root, bg="#1a1a2e", highlightbackground="#2a2a4e", highlightthickness=1)
        llm_frame.pack(fill="x", padx=20, pady=10)

        llm_inner = tk.Frame(llm_frame, bg="#1a1a2e")
        llm_inner.pack(fill="x", padx=15, pady=12)

        tk.Label(
            llm_inner,
            text="ğŸ¤– Local LLM (Ollama)",
            font=("Segoe UI", 11, "bold"),
            fg="#ffffff",
            bg="#1a1a2e"
        ).pack(side="left")

        self.llm_status = tk.Label(
            llm_inner,
            text="í™•ì¸ ì¤‘...",
            font=("Segoe UI", 11),
            fg="#888888",
            bg="#1a1a2e"
        )
        self.llm_status.pack(side="right")

        # LLM ë²„íŠ¼ í–‰
        llm_btn_frame = tk.Frame(llm_frame, bg="#1a1a2e")
        llm_btn_frame.pack(fill="x", padx=15, pady=(0, 10))

        self.btn_start_ollama = tk.Button(
            llm_btn_frame,
            text="â–¶ ì‹œì‘",
            font=("Segoe UI", 9),
            bg="#4ecca3",
            fg="white",
            bd=0,
            cursor="hand2",
            width=8,
            command=self.start_ollama
        )
        self.btn_start_ollama.pack(side="left", padx=(0, 5))

        self.btn_stop_ollama = tk.Button(
            llm_btn_frame,
            text="â¹ ì¤‘ì§€",
            font=("Segoe UI", 9),
            bg="#e94560",
            fg="white",
            bd=0,
            cursor="hand2",
            width=8,
            command=self.stop_ollama
        )
        self.btn_stop_ollama.pack(side="left", padx=(0, 5))

        self.llm_model_label = tk.Label(
            llm_btn_frame,
            text="",
            font=("Segoe UI", 9),
            fg="#666666",
            bg="#1a1a2e"
        )
        self.llm_model_label.pack(side="right")

        # ë²„íŠ¼ ì˜ì—­
        btn_frame = tk.Frame(self.root, bg="#0f0f1a")
        btn_frame.pack(fill="x", padx=20, pady=10)

        btn_style = {
            "font": ("Segoe UI", 11, "bold"),
            "width": 20,
            "height": 2,
            "cursor": "hand2",
            "bd": 0,
            "activeforeground": "white"
        }

        # ë²„íŠ¼ í–‰ 1
        row1 = tk.Frame(btn_frame, bg="#0f0f1a")
        row1.pack(fill="x", pady=5)

        self.btn_run = tk.Button(
            row1,
            text="â–¶  ì§€ê¸ˆ ì‹¤í–‰",
            bg="#4ecca3",
            fg="white",
            activebackground="#3db892",
            command=self.run_now,
            **btn_style
        )
        self.btn_run.pack(side="left", expand=True, fill="x", padx=(0, 5))

        btn_stop = tk.Button(
            row1,
            text="â¹  ì¤‘ì§€",
            bg="#e94560",
            fg="white",
            activebackground="#d13652",
            command=self.stop_execution,
            **btn_style
        )
        btn_stop.pack(side="right", expand=True, fill="x", padx=(5, 0))

        # ë²„íŠ¼ í–‰ 2
        row2 = tk.Frame(btn_frame, bg="#0f0f1a")
        row2.pack(fill="x", pady=5)

        btn_enable = tk.Button(
            row2,
            text="â°  ìë™ì‹¤í–‰ ì¼œê¸°",
            bg="#0f4c75",
            fg="white",
            activebackground="#0d3d5f",
            command=self.enable_schedule,
            **btn_style
        )
        btn_enable.pack(side="left", expand=True, fill="x", padx=(0, 5))

        btn_disable = tk.Button(
            row2,
            text="â¸  ìë™ì‹¤í–‰ ë„ê¸°",
            bg="#3d3d3d",
            fg="white",
            activebackground="#2d2d2d",
            command=self.disable_schedule,
            **btn_style
        )
        btn_disable.pack(side="right", expand=True, fill="x", padx=(5, 0))

        # ë²„íŠ¼ í–‰ 3 - ê´‘ê³  ê´€ë¦¬
        row3 = tk.Frame(btn_frame, bg="#0f0f1a")
        row3.pack(fill="x", pady=5)

        btn_reset_ads = tk.Button(
            row3,
            text="ğŸ—‘  ê´‘ê³  ìŠ¬ë¡¯ ì´ˆê¸°í™”",
            bg="#ff6b6b",
            fg="white",
            activebackground="#ee5a5a",
            command=self.reset_ads,
            **btn_style
        )
        btn_reset_ads.pack(expand=True, fill="x")

        # ë¡œê·¸ ì˜ì—­ (íƒ­)
        log_container = tk.Frame(self.root, bg="#0f0f1a")
        log_container.pack(fill="both", expand=True, padx=20, pady=10)

        # íƒ­ ìŠ¤íƒ€ì¼ ì„¤ì • (Windows í˜¸í™˜)
        style = ttk.Style()
        style.theme_use('default')  # ê¸°ë³¸ í…Œë§ˆ ì‚¬ìš© (Windows í…Œë§ˆ ë¬´ì‹œ)
        style.configure("Dark.TNotebook", background="#0f0f1a", borderwidth=0)
        style.configure("Dark.TNotebook.Tab",
                        background="#2a2a4e",
                        foreground="#ffffff",
                        padding=[15, 8],
                        font=("Segoe UI", 10, "bold"))
        style.map("Dark.TNotebook.Tab",
                  background=[("selected", "#4ecca3")],
                  foreground=[("selected", "#000000")])

        # ë…¸íŠ¸ë¶ (íƒ­ ì»¨í…Œì´ë„ˆ)
        self.log_notebook = ttk.Notebook(log_container, style="Dark.TNotebook")
        self.log_notebook.pack(fill="both", expand=True)

        # íƒ­ 1: ë©”ì¸ ë¡œê·¸
        main_log_frame = tk.Frame(self.log_notebook, bg="#1a1a2e")
        self.log_notebook.add(main_log_frame, text="ğŸ“‹ ì‹¤í–‰ ë¡œê·¸")

        log_header = tk.Frame(main_log_frame, bg="#1a1a2e")
        log_header.pack(fill="x", pady=5, padx=5)

        btn_clear = tk.Button(
            log_header,
            text="ì§€ìš°ê¸°",
            font=("Segoe UI", 9),
            bg="#2a2a4e",
            fg="#888888",
            bd=0,
            cursor="hand2",
            command=self.clear_log
        )
        btn_clear.pack(side="right")

        self.log_text = scrolledtext.ScrolledText(
            main_log_frame,
            font=("Consolas", 9),
            bg="#1a1a2e",
            fg="#cccccc",
            insertbackground="#cccccc",
            selectbackground="#3d3d5c",
            wrap=tk.WORD,
            height=12,
            state="disabled",
            bd=0,
            highlightthickness=1,
            highlightbackground="#2a2a4e"
        )
        self.log_text.pack(fill="both", expand=True, padx=5, pady=(0, 5))

        # íƒ­ 2: Local LLM ë¡œê·¸
        llm_log_frame = tk.Frame(self.log_notebook, bg="#1a1a2e")
        self.log_notebook.add(llm_log_frame, text="ğŸ¤– Local LLM ë¡œê·¸")

        llm_log_header = tk.Frame(llm_log_frame, bg="#1a1a2e")
        llm_log_header.pack(fill="x", pady=5, padx=5)

        btn_clear_llm = tk.Button(
            llm_log_header,
            text="ì§€ìš°ê¸°",
            font=("Segoe UI", 9),
            bg="#2a2a4e",
            fg="#888888",
            bd=0,
            cursor="hand2",
            command=self.clear_llm_log
        )
        btn_clear_llm.pack(side="right")

        self.llm_log_text = scrolledtext.ScrolledText(
            llm_log_frame,
            font=("Consolas", 9),
            bg="#1a1a2e",
            fg="#cccccc",
            insertbackground="#cccccc",
            selectbackground="#3d3d5c",
            wrap=tk.WORD,
            height=12,
            state="disabled",
            bd=0,
            highlightthickness=1,
            highlightbackground="#2a2a4e"
        )
        self.llm_log_text.pack(fill="both", expand=True, padx=5, pady=(0, 5))

        # íƒœê·¸ ì„¤ì • (ë©”ì¸ ë¡œê·¸)
        self.log_text.tag_config("time", foreground="#666666")
        self.log_text.tag_config("info", foreground="#4ecca3")
        self.log_text.tag_config("warn", foreground="#f9a825")
        self.log_text.tag_config("error", foreground="#e94560")
        self.log_text.tag_config("success", foreground="#4ecca3")

        # íƒœê·¸ ì„¤ì • (LLM ë¡œê·¸)
        self.llm_log_text.tag_config("time", foreground="#666666")
        self.llm_log_text.tag_config("info", foreground="#4ecca3")
        self.llm_log_text.tag_config("warn", foreground="#f9a825")
        self.llm_log_text.tag_config("error", foreground="#e94560")
        self.llm_log_text.tag_config("success", foreground="#4ecca3")

        # í”„ë¡œê·¸ë ˆìŠ¤ ë°”
        self.progress = ttk.Progressbar(
            self.root,
            mode="indeterminate",
            length=460
        )

        # í•˜ë‹¨ ì •ë³´
        footer = tk.Label(
            self.root,
            text="v1.0 | ì•± ì•„ì´ë””ì–´ ë¦¬í¬í„°",
            font=("Segoe UI", 9),
            fg="#444444",
            bg="#0f0f1a"
        )
        footer.pack(pady=(5, 15))

        # ì‹œì‘ ë¡œê·¸
        self.log("í”„ë¡œê·¸ë¨ ì‹œì‘", "info")

    def log(self, message, level="info"):
        """ë¡œê·¸ íì— ë©”ì‹œì§€ ì¶”ê°€"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.log_queue.put((timestamp, message, level))

    def process_log_queue(self):
        """ë¡œê·¸ í ì²˜ë¦¬"""
        try:
            while True:
                timestamp, message, level = self.log_queue.get_nowait()
                self.log_text.config(state="normal")
                self.log_text.insert(tk.END, f"[{timestamp}] ", "time")
                self.log_text.insert(tk.END, f"{message}\n", level)
                self.log_text.see(tk.END)
                self.log_text.config(state="disabled")
        except queue.Empty:
            pass
        self.root.after(100, self.process_log_queue)

    def clear_log(self):
        """ë¡œê·¸ ì§€ìš°ê¸°"""
        self.log_text.config(state="normal")
        self.log_text.delete(1.0, tk.END)
        self.log_text.config(state="disabled")
        self.log("ë¡œê·¸ ì´ˆê¸°í™”", "info")

    def update_status(self):
        """ìë™ì‹¤í–‰ ìƒíƒœ í‘œì‹œ"""
        if self.auto_run_enabled:
            self.schedule_status.config(text="ì¼œì§ (ë§¤ì¼ 00:00)", fg="#4ecca3")
        else:
            self.schedule_status.config(text="êº¼ì§", fg="#888888")

        # ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê°„ í‘œì‹œ
        if self.last_auto_run_date:
            self.last_run_label.config(text=f"ë§ˆì§€ë§‰ ìë™ì‹¤í–‰: {self.last_auto_run_date}")

        # 5ì´ˆë§ˆë‹¤ ìƒíƒœ ê°±ì‹ 
        self.root.after(5000, self.update_status)

    def check_midnight(self):
        """ìì • ì²´í¬ (ë§¤ 30ì´ˆë§ˆë‹¤)"""
        now = datetime.now()
        today = now.strftime("%Y-%m-%d")

        # ìì •~00:05 ì‚¬ì´ì´ê³ , ì˜¤ëŠ˜ ì•„ì§ ì‹¤í–‰ ì•ˆ í–ˆìœ¼ë©´ ì‹¤í–‰
        if (self.auto_run_enabled and
            now.hour == 0 and now.minute < 5 and
            self.last_auto_run_date != today and
            not self.is_running):

            self.last_auto_run_date = today
            self.log("", "info")
            self.log("ğŸ•› ìì • ìë™ì‹¤í–‰ ì‹œì‘!", "success")
            self.run_now()

        # 30ì´ˆë§ˆë‹¤ ì²´í¬
        self.root.after(30000, self.check_midnight)

    def set_running(self, running):
        """ì‹¤í–‰ ìƒíƒœ ì„¤ì •"""
        self.is_running = running
        if running:
            self.status_dot.config(fg="#4ecca3")
            self.status_text.config(text="ì‹¤í–‰ ì¤‘", fg="#4ecca3")
            self.btn_run.config(state="disabled", bg="#2a2a4e")
            self.progress.pack(pady=(0, 10))
            self.progress.start(10)
        else:
            self.status_dot.config(fg="#888888")
            self.status_text.config(text="ëŒ€ê¸° ì¤‘", fg="#888888")
            self.btn_run.config(state="normal", bg="#4ecca3")
            self.progress.stop()
            self.progress.pack_forget()

    def run_now(self):
        """ì§€ê¸ˆ ì‹¤í–‰"""
        if self.is_running:
            return

        # Ollama ì‹¤í–‰ ì²´í¬ & ìë™ ì‹œì‘
        if not check_ollama_running():
            self.log("ğŸ¤– Local LLM(Ollama)ì´ êº¼ì ¸ ìˆì–´ ìë™ ì‹œì‘í•©ë‹ˆë‹¤...", "info")
            self.llm_log("íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ ìœ„í•´ ìë™ ì‹œì‘...", "info")

            def on_ollama_ready(success):
                if success:
                    self.log("âœ… Ollama + ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ, íŒŒì´í”„ë¼ì¸ ì§„í–‰", "success")
                    self._run_pipeline()
                else:
                    self.log("âŒ Ollama ì‹œì‘ ì‹¤íŒ¨, íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨", "error")

            self.start_ollama(callback=on_ollama_ready)
            return

        # ì„œë²„ëŠ” ì‹¤í–‰ ì¤‘ì´ì§€ë§Œ ëª¨ë¸ì´ ë¡œë“œ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ ì›œì—…
        running_models = get_running_models()
        model_loaded = DEFAULT_MODEL in running_models or any(DEFAULT_MODEL.split(':')[0] in m for m in running_models)

        if not model_loaded:
            self.log(f"ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘: {DEFAULT_MODEL}...", "info")
            self.llm_log(f"ëª¨ë¸ ì›œì—… ì‹œì‘: {DEFAULT_MODEL}", "info")

            def warmup_task():
                if warmup_model(DEFAULT_MODEL):
                    self.log("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ, íŒŒì´í”„ë¼ì¸ ì§„í–‰", "success")
                    self.llm_log(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ", "success")
                    self.root.after(0, self._run_pipeline)
                else:
                    self.log("âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ê·¸ë˜ë„ ì§„í–‰ ì‹œë„", "warn")
                    self.root.after(0, self._run_pipeline)

            threading.Thread(target=warmup_task, daemon=True).start()
            return

        self._run_pipeline()

    def _run_pipeline(self):
        """ì‹¤ì œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        def task():
            self.set_running(True)
            self.current_process = None

            # (cmd, desc, detail, optional) - optional=Trueë©´ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            steps = [
                # 1. í”¼ë“œë°± ë¶„ì„ ë¦¬í¬íŠ¸ (ì„ íƒ)
                ("node feedback/feedbackAnalyzer.js report > output/feedback_report.md", "í”¼ë“œë°± ë¶„ì„", "í”¼ë“œë°± íŒ¨í„´/íŠ¸ë Œë“œ ë¶„ì„", True),
                # 2. í”¼ë“œë°± ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ê°œì„  (ì„ íƒ)
                ("node feedback/promptImprover.js run", "í”„ë¡¬í”„íŠ¸ ê°œì„ ", "í”¼ë“œë°± ê¸°ë°˜ ìë™ ê°œì„ ", True),
                # 3. ì•± ìˆ˜ì§‘ (í•„ìˆ˜)
                ("npm run collect", "ì•± ë°ì´í„° ìˆ˜ì§‘", "iOS/Android ì‹ ê·œ ì•± ìŠ¤í¬ë˜í•‘", False),
                # 4. Claude ë¶„ì„ - Dynamic Prompt + ì‹¬ì¸µ ë¶„ì„ (í•„ìˆ˜)
                ("npm run analyze", "Claude AI ë¶„ì„", "Dynamic Prompt + í’ˆì§ˆ ì²´í¬ + ì‹¬ì¸µ ë¶„ì„", False),
                # 5. íŠ¸ë Œë“œ ë¶„ì„ (ì„ íƒ)
                ("node scripts/trendDetector.js", "íŠ¸ë Œë“œ ë¶„ì„", "ì£¼ê°„ íŠ¸ë Œë“œ ê°ì§€", True),
                # 6. ë¦¬í¬íŠ¸ ì €ì¥ (í•„ìˆ˜)
                ("npm run save", "ë¦¬í¬íŠ¸ ì €ì¥", "JSON íŒŒì¼ ìƒì„±", False),
                # 7. Git í‘¸ì‹œ (í•„ìˆ˜)
                ("git add web/data/reports/*.json output/*.json output/*.md && git commit -m \"Daily report\" && git push origin main", "GitHub ì—…ë¡œë“œ", "ë¦¬í¬íŠ¸ í‘¸ì‹œ", False),
                # 8. Vercel ë°°í¬ (í•„ìˆ˜)
                ("cd web && vercel --prod --yes", "Vercel ë°°í¬", "ì›¹ì‚¬ì´íŠ¸ ì—…ë°ì´íŠ¸", False),
                # 9. ì¹´ì¹´ì˜¤í†¡ ì „ì†¡ (ì„ íƒ)
                ("npm run kakao:send", "ì¹´ì¹´ì˜¤í†¡ ì „ì†¡", "ìš”ì•½ ë©”ì‹œì§€ ë°œì†¡", True)
            ]

            total_steps = len(steps)
            start_time = time.time()

            try:
                self.log("â”" * 45, "info")
                self.log("ğŸš€ ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹œì‘ (9ë‹¨ê³„)", "info")
                self.log("â”" * 45, "info")

                for i, (cmd, desc, detail, optional) in enumerate(steps):
                    if not self.is_running:
                        self.log("âš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ì§€ë¨", "warn")
                        break

                    step_start = time.time()
                    self.log("", "info")
                    opt_tag = " (ì„ íƒ)" if optional else ""
                    self.log(f"â–¶ [{i+1}/{total_steps}] {desc}{opt_tag}", "info")
                    self.log(f"  â”” {detail}", "info")

                    process = subprocess.Popen(
                        cmd,
                        cwd=PROJECT_DIR,
                        shell=True,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.STDOUT,
                        text=True,
                        encoding='utf-8',
                        errors='replace',
                        creationflags=subprocess.CREATE_NO_WINDOW
                    )
                    self.current_process = process

                    # ì‹¤ì‹œê°„ ì¶œë ¥
                    for line in iter(process.stdout.readline, ''):
                        if line.strip():
                            clean_line = line.strip()
                            # ì¤‘ìš” ì •ë³´ë§Œ í‘œì‹œ
                            if any(key in clean_line for key in ['âœ…', 'âœ“', 'ì™„ë£Œ', 'success', 'Complete', 'í’ˆì§ˆ']):
                                self.log(f"    âœ… {clean_line}", "success")
                            elif any(key in clean_line for key in ['âŒ', 'âœ—', 'ì‹¤íŒ¨', 'error', 'Error', 'fail']):
                                self.log(f"    âŒ {clean_line}", "error")
                            elif any(key in clean_line for key in ['âš ', 'ê²½ê³ ', 'warn', 'Warning', 'ìŠ¤í‚µ']):
                                self.log(f"    âš ï¸ {clean_line}", "warn")
                            elif any(key in clean_line for key in ['iOS:', 'Android:', 'ê°œ ', 'ì„ ì •', 'KB', 'ìˆ˜ì§‘', 'ë¶„ì„', 'ì €ì¥', 'ì „ì†¡', 'ë°°í¬', 'Production:', 'Aliased:', 'íŠ¸ë Œë“œ', 'í…Œë§ˆ', 'ì‹œë„']):
                                self.log(f"    ğŸ“Š {clean_line}", "info")
                            elif any(key in clean_line for key in ['â³', 'ì¤‘...', 'ing...', 'ëŒ€ê¸°', 'ë¡œë“œ']):
                                self.log(f"    â³ {clean_line}", "warn")

                    process.wait()
                    step_time = time.time() - step_start

                    if process.returncode != 0:
                        if optional:
                            self.log(f"  âš ï¸ ìŠ¤í‚µë¨ ({step_time:.1f}ì´ˆ)", "warn")
                        else:
                            self.log(f"  âŒ ì‹¤íŒ¨ (ì½”ë“œ: {process.returncode}, {step_time:.1f}ì´ˆ)", "error")
                            raise Exception(f"{desc} ì‹¤íŒ¨")
                    else:
                        self.log(f"  âœ… ì™„ë£Œ ({step_time:.1f}ì´ˆ)", "success")

                if self.is_running:
                    total_time = time.time() - start_time
                    self.log("", "info")
                    self.log("â”" * 45, "info")
                    self.log("ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!", "success")
                    self.log(f"  ì´ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„", "info")
                    self.log("  ğŸ“± ì¹´ì¹´ì˜¤í†¡ì„ í™•ì¸í•˜ì„¸ìš”", "info")
                    self.log("  ğŸŒ ì›¹ì‚¬ì´íŠ¸ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤", "info")
                    self.log("â”" * 45, "info")

            except Exception as e:
                total_time = time.time() - start_time
                self.log("", "info")
                self.log("â”" * 45, "info")
                self.log(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "error")
                self.log(f"  ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„", "info")
                self.log("â”" * 45, "info")
            finally:
                # ëª¨ë¸ ì–¸ë¡œë“œ (GPU ë©”ëª¨ë¦¬ í•´ì œ)
                self.log("ğŸ”„ Local LLM ëª¨ë¸ ì–¸ë¡œë“œ ì¤‘...", "info")
                self.llm_log("íŒŒì´í”„ë¼ì¸ ì™„ë£Œ, ëª¨ë¸ ì–¸ë¡œë“œ ì¤‘...", "info")
                if unload_model(DEFAULT_MODEL):
                    self.log("âœ… ëª¨ë¸ ì–¸ë¡œë“œ ì™„ë£Œ (GPU ë©”ëª¨ë¦¬ í•´ì œ)", "success")
                    self.llm_log("âœ… ëª¨ë¸ ì–¸ë¡œë“œ ì™„ë£Œ", "success")
                else:
                    self.llm_log("â„¹ï¸ ëª¨ë¸ì´ ì´ë¯¸ ì–¸ë¡œë“œë˜ì—ˆê±°ë‚˜ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹˜", "info")

                self.root.after(0, lambda: self.set_running(False))
                self.current_process = None

        self.current_process = None
        threading.Thread(target=task, daemon=True).start()

    def stop_execution(self):
        """ì‹¤í–‰ ì¤‘ì§€"""
        if self.is_running:
            self.is_running = False
            if hasattr(self, 'current_process') and self.current_process:
                try:
                    self.current_process.terminate()
                except:
                    pass
            self.log("ì¤‘ì§€ ìš”ì²­ë¨...", "warn")

    def enable_schedule(self):
        """ìë™ì‹¤í–‰ ì¼œê¸°"""
        self.auto_run_enabled = True
        self.log("ìë™ì‹¤í–‰ ì¼œì§ (ë§¤ì¼ 00:00)", "success")
        self.log("  â”” í”„ë¡œê·¸ë¨ì´ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ ë™ì‘í•©ë‹ˆë‹¤", "info")

    def disable_schedule(self):
        """ìë™ì‹¤í–‰ ë„ê¸°"""
        self.auto_run_enabled = False
        self.log("ìë™ì‹¤í–‰ êº¼ì§", "info")

    def reset_ads(self):
        """ê´‘ê³  ìŠ¬ë¡¯ ì´ˆê¸°í™”"""
        def task():
            self.log("", "info")
            self.log("ğŸ—‘ ê´‘ê³  ìŠ¬ë¡¯ ì´ˆê¸°í™” ì‹œì‘...", "info")

            try:
                # API URL (ë°°í¬ëœ ì‚¬ì´íŠ¸)
                url = "https://dailyapp.vercel.app/api/ad/slots"

                req = urllib.request.Request(url, method='DELETE')
                req.add_header('Content-Type', 'application/json')

                with urllib.request.urlopen(req, timeout=10) as response:
                    result = json.loads(response.read().decode('utf-8'))

                    if result.get('success'):
                        self.log("âœ… ëª¨ë“  ê´‘ê³  ìŠ¬ë¡¯ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!", "success")
                    else:
                        self.log(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}", "error")

            except urllib.error.URLError as e:
                self.log(f"âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}", "error")
            except Exception as e:
                self.log(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "error")

        threading.Thread(target=task, daemon=True).start()

    # ========== Local LLM (Ollama) ê´€ë ¨ ==========

    def llm_log(self, message, level="info"):
        """LLM ë¡œê·¸ íì— ë©”ì‹œì§€ ì¶”ê°€"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.llm_log_queue.put((timestamp, message, level))

    def process_llm_log_queue(self):
        """LLM ë¡œê·¸ í ì²˜ë¦¬"""
        try:
            while True:
                timestamp, message, level = self.llm_log_queue.get_nowait()
                self.llm_log_text.config(state="normal")
                self.llm_log_text.insert(tk.END, f"[{timestamp}] ", "time")
                self.llm_log_text.insert(tk.END, f"{message}\n", level)
                self.llm_log_text.see(tk.END)
                self.llm_log_text.config(state="disabled")
        except queue.Empty:
            pass
        self.root.after(100, self.process_llm_log_queue)

    def clear_llm_log(self):
        """LLM ë¡œê·¸ ì§€ìš°ê¸°"""
        self.llm_log_text.config(state="normal")
        self.llm_log_text.delete(1.0, tk.END)
        self.llm_log_text.config(state="disabled")
        self.llm_log("ë¡œê·¸ ì´ˆê¸°í™”", "info")

    def check_ollama_status(self):
        """Ollama ìƒíƒœ ì£¼ê¸°ì  ì²´í¬"""
        def check():
            running = check_ollama_running()
            self.ollama_running = running

            if running:
                # ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ í™•ì¸
                running_models = get_running_models()
                model_loaded = DEFAULT_MODEL in running_models or any(DEFAULT_MODEL.split(':')[0] in m for m in running_models)

                if model_loaded:
                    self.llm_status.config(text="ëª¨ë¸ ë¡œë“œë¨", fg="#4ecca3")
                    self.llm_model_label.config(text=f"âœ“ {DEFAULT_MODEL.split(':')[0]}", fg="#4ecca3")
                else:
                    self.llm_status.config(text="ì„œë²„ë§Œ ì‹¤í–‰ ì¤‘", fg="#f9a825")
                    self.llm_model_label.config(text="ëª¨ë¸ ëŒ€ê¸° ì¤‘", fg="#888888")

                self.btn_start_ollama.config(state="disabled", bg="#2a2a4e")
                self.btn_stop_ollama.config(state="normal", bg="#e94560")
            else:
                self.llm_status.config(text="ì¤‘ì§€ë¨", fg="#e94560")
                self.btn_start_ollama.config(state="normal", bg="#4ecca3")
                self.btn_stop_ollama.config(state="disabled", bg="#2a2a4e")
                self.llm_model_label.config(text="", fg="#888888")

        threading.Thread(target=check, daemon=True).start()
        # 5ì´ˆë§ˆë‹¤ ì²´í¬
        self.root.after(5000, self.check_ollama_status)

    def start_ollama(self, callback=None):
        """Ollama ì„œë²„ ì‹œì‘ (ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ìŠ¤í‚µ)"""
        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ì§€ ì²´í¬
        if check_ollama_running():
            self.llm_log("â„¹ï¸ Ollamaê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤", "info")
            if callback:
                callback(True)
            return

        def task():
            self.llm_log("Ollama ì„œë²„ ì‹œì‘ ì¤‘...", "info")

            try:
                # Ollama ì„œë²„ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
                self.ollama_process = subprocess.Popen(
                    "ollama serve",
                    shell=True,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    encoding='utf-8',
                    errors='replace',
                    creationflags=subprocess.CREATE_NO_WINDOW
                )

                # ì¶œë ¥ ì½ê¸° ìŠ¤ë ˆë“œ
                def read_output():
                    for line in iter(self.ollama_process.stdout.readline, ''):
                        if line.strip():
                            clean_line = line.strip()
                            if 'error' in clean_line.lower():
                                self.llm_log(clean_line, "error")
                            elif 'warning' in clean_line.lower():
                                self.llm_log(clean_line, "warn")
                            else:
                                self.llm_log(clean_line, "info")

                threading.Thread(target=read_output, daemon=True).start()

                # ì‹œì‘ ëŒ€ê¸° (ìµœëŒ€ 10ì´ˆ)
                for _ in range(10):
                    time.sleep(1)
                    if check_ollama_running():
                        break

                if check_ollama_running():
                    self.llm_log("âœ… Ollama ì„œë²„ ì‹œì‘ë¨", "success")

                    # ëª¨ë¸ ì›œì—… (ë¯¸ë¦¬ ë¡œë“œ)
                    self.llm_log(f"ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘: {DEFAULT_MODEL}...", "info")
                    if warmup_model(DEFAULT_MODEL):
                        self.llm_log(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {DEFAULT_MODEL}", "success")
                    else:
                        self.llm_log(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ (ì²« ìš”ì²­ ì‹œ ìë™ ë¡œë“œë¨)", "warn")

                    if callback:
                        callback(True)
                else:
                    self.llm_log("âš ï¸ Ollama ì„œë²„ ì‹œì‘ ì‹¤íŒ¨", "warn")
                    if callback:
                        callback(False)

            except Exception as e:
                self.llm_log(f"âŒ ì‹œì‘ ì‹¤íŒ¨: {str(e)}", "error")
                if callback:
                    callback(False)

        threading.Thread(target=task, daemon=True).start()

    def stop_ollama(self):
        """Ollama ì„œë²„ ì¤‘ì§€"""
        def task():
            self.llm_log("Ollama ì„œë²„ ì¤‘ì§€ ì¤‘...", "info")

            try:
                # taskkillë¡œ ì¢…ë£Œ (Windows)
                subprocess.run(
                    "taskkill /F /IM ollama.exe",
                    shell=True,
                    capture_output=True,
                    creationflags=subprocess.CREATE_NO_WINDOW
                )

                if self.ollama_process:
                    try:
                        self.ollama_process.terminate()
                    except:
                        pass
                    self.ollama_process = None

                time.sleep(1)

                if not check_ollama_running():
                    self.llm_log("âœ… Ollama ì„œë²„ ì¤‘ì§€ë¨", "success")
                else:
                    self.llm_log("âš ï¸ Ollama ì„œë²„ê°€ ì•„ì§ ì‹¤í–‰ ì¤‘ì¼ ìˆ˜ ìˆìŒ", "warn")

            except Exception as e:
                self.llm_log(f"âŒ ì¤‘ì§€ ì‹¤íŒ¨: {str(e)}", "error")

        threading.Thread(target=task, daemon=True).start()

    def run(self):
        self.root.mainloop()

if __name__ == "__main__":
    app = DailyAppManager()
    app.run()
